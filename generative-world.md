# üåç Generative World Models

Generative world models allow embodied AI agents to build internal representations of their environment and simulate possible futures before acting. 

They are a cornerstone of model-based reinforcement learning, safe planning, and adaptive robotics.



## üìÑ Key Papers

- [World Models (Ha & Schmidhuber, 2018)](https://arxiv.org/abs/1803.10122) ‚Äî A pioneering study where agents learn compressed generative representations of their environments.
- [PlaNet: Learning Latent Dynamics for Planning (Hafner et al., 2019)](https://arxiv.org/abs/1811.04551) ‚Äî Demonstrates planning capabilities via latent dynamics models.
- [Dreamer: Scalable Reinforcement Learning Using World Models (Hafner et al., 2020)](https://arxiv.org/abs/1912.01603) ‚Äî Shows how agents can learn from imagined rollouts generated by world models.
- [DreamerV3 (Hafner et al., 2023)](https://arxiv.org/abs/2301.04104) ‚Äî Extends Dreamer for generalization across a broader range of environments.
- [Genie: Generative Interactive Environments (Bruce et al., 2024)](https://arxiv.org/abs/2402.15391) ‚Äî The first unsupervised interactive environment model learned from internet videos, with frame-level control.
- [Genie-2: A Large-Scale Foundation World Model (DeepMind, 2024)](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/) ‚Äî Generates diverse, playable 3D worlds from image prompts.
- [SIMA: A Generalist AI Agent for 3D Virtual Environments (DeepMind, 2024)](https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/) ‚Äî A language-guided agent that can understand and act in multiple virtual 3D environments using natural instructions. 
- [Embodied AI Agents: Modeling the World (Fung et al., 2025)](https://arxiv.org/abs/2506.22355) ‚Äî A wide-ranging conceptual framework on how world modeling can unify embodied agent design. 
- [Genie-3: A New Frontier for World Models (DeepMind, 2025)](https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/) ‚Äî The first world model supporting real-time interaction and improved realism. 
- [VC-1: Robots Learning by Video Simulation + Artificial Visual Cortex (Meta AI, 2024)](https://ai.meta.com/blog/robots-learning-video-simulation-artificial-visual-cortex-vc-1/) ‚Äî Robots learn through simulated video worlds trained to mimic visual cortex processing.
- [DiffuseBot: Breeding Soft Robots with Physics-Augmented Generative Diffusion (2023)](https://arxiv.org/abs/2311.17053) ‚Äî Uses diffusion-based generative models to evolve soft robot morphologies with physics constraints. 
- [RoboGen: Infinite Data for Robot Learning via Generative Simulation (2023)](https://arxiv.org/abs/2311.01455) ‚Äî Explores the use of generative simulation to produce vast training data for robot learning.



## üíª Open-Source Repositories
- [Genesis](https://github.com/Genesis-Embodied-AI/Genesis)
- [World Models Experiments (Ha & Schmidhuber)](https://github.com/hardmaru/WorldModelsExperiments)
- [DreamerV3 (reimplementation)](https://github.com/danijar/dreamerv3)
- []
- [Mujoco + World Models Examples](https://github.com/openai/mujoco-py)
- [PlaNet Implementation (PyTorch)](https://github.com/Kaixhin/PlaNet)
- [EmbodiedGen](https://github.com/HorizonRobotics/EmbodiedGen)
- [awesome-world-models-for-robots](https://github.com/operator22th/awesome-world-models-for-robots)


## üõ†Ô∏è Tools or Libraries
- [DeepMind Control Suite](https://github.com/deepmind/dm_control) ‚Äì Google DeepMind's software stack for physics-based simulation and RL environment
- [OpenAI Gym / Gymnasium](https://gymnasium.farama.org/) ‚Äì Widely used RL environment suite.
- [Habitat-Sim](https://aihabitat.org/) ‚Äì Embodied AI and navigation simulator.
- [MuJoCo](https://mujoco.org/) ‚Äì High-performance physics engine for model-based RL.
- [PyBullet](https://pybullet.org/) ‚Äì Physics dataset simulator for robotics and RL.

## üìä Benchmarks and Datasets


## üéì Courses & Tutorials
- [CS285: Deep Reinforcement Learning (UC Berkeley)](http://rail.eecs.berkeley.edu/deeprlcourse/)
- [MIT 6.S191: Introduction to Deep Learning](http://introtodeeplearning.com/)
- [DreamerV3 Colab Tutorial](https://colab.research.google.com/github/danijar/dreamerv3/blob/main/notebooks/dreamerv3.ipynb)
- [Spinning Up in Deep RL (OpenAI)](https://spinningup.openai.com/en/latest/)


## üìù Blogs & Explanations
- [Lil‚ÄôLog: A Tour of World Models](https://lilianweng.github.io/posts/2019-07-10-world-models/)
- [Distill: Understanding RL through Imagination](https://distill.pub/)
- [DeepMind Blog: Genie](https://deepmind.google/discover/blog/genie/)
- [HunyuanWorld-Voyager Release Post](https://arxiv.org/abs/2408.14506)


---

üìå *This page is part of the [Robotics Resource Hub](./README.md). Updated biweekly with new resources.*
